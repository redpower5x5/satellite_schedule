{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n",
    "from optapy import problem_fact, planning_id\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "area_path = '../dataset/area_work/'\n",
    "path_to_facility= '../dataset/facility_timing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read visibility to facilites data\n",
    "dfs = []\n",
    "for path, subdirs, files in os.walk(path_to_facility):\n",
    "    for name in files:\n",
    "        if '.csv' in name:\n",
    "            facility_csv_path = os.path.join(path, name)\n",
    "            df = pd.read_csv(facility_csv_path, index_col=0)\n",
    "            df['Start Time (UTCG)'] = pd.to_datetime(df['Start Time (UTCG)'], format='%d %b %Y %H:%M:%S.%f')\n",
    "            df['Stop Time (UTCG)'] = pd.to_datetime(df['Stop Time (UTCG)'], format='%d %b %Y %H:%M:%S.%f')\n",
    "            naming = name.split('-To-')\n",
    "            df['facility'] = naming[0]\n",
    "            sat_name = naming[1].split('.')[0]\n",
    "            orbit_num = int(sat_name.split('_11')[1][:-2])\n",
    "            if orbit_num > 5:\n",
    "                sat_name = 'ZorkySat_' + sat_name.split('_')[1]\n",
    "            df['sat_name'] = sat_name\n",
    "            dfs.append(df)\n",
    "\n",
    "facilities_df = pd.concat(dfs)\n",
    "facilities_df = facilities_df.sort_values(by=['Start Time (UTCG)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read area data\n",
    "dfs = []\n",
    "for path, subdirs, files in os.walk(area_path):\n",
    "    for name in files:\n",
    "        if '_' in name:\n",
    "            area_csv_path = os.path.join(path, name)\n",
    "            df = pd.read_csv(area_csv_path, index_col=0)\n",
    "            df['Start Time (UTCG)'] = pd.to_datetime(df['Start Time (UTCG)'], format='%d %b %Y %H:%M:%S.%f')\n",
    "            df['Stop Time (UTCG)'] = pd.to_datetime(df['Stop Time (UTCG)'], format='%d %b %Y %H:%M:%S.%f')\n",
    "            df['sat_name'] = name.split('.')[0]\n",
    "            dfs.append(df)\n",
    "\n",
    "area_df = pd.concat(dfs)\n",
    "area_df = area_df.sort_values(by=['Start Time (UTCG)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = area_df['Start Time (UTCG)'].min()\n",
    "upper_bound = area_df[area_df['Start Time (UTCG)'] > datetime(2027, 6, 3)]['Start Time (UTCG)'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_df = area_df[(area_df['Start Time (UTCG)'] >= lower_bound) & (area_df['Start Time (UTCG)'] < upper_bound)]\n",
    "facilities_df = facilities_df[(facilities_df['Start Time (UTCG)'] > lower_bound) & (facilities_df['Start Time (UTCG)'] < upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate data filmed by sat (4Gbit/sec) in Tbytes\n",
    "area_df['Data'] = area_df['Duration (sec)'] * 4 / 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_names = area_df['sat_name'].unique()\n",
    "dfs = []\n",
    "i = 0\n",
    "for sat_name in sat_names:\n",
    "    i += 1\n",
    "    print(f'{i}/{len(sat_names)} - {sat_name}')\n",
    "    area_df_sat = area_df[area_df['sat_name'] == sat_name]\n",
    "    facilities_df_sat = facilities_df[facilities_df['sat_name'] == sat_name]\n",
    "    filtered_facilities_df = facilities_df_sat.copy()\n",
    "    for _, area_row in area_df_sat.iterrows():\n",
    "        cut_start = area_row['Start Time (UTCG)']\n",
    "        cut_stop = area_row['Stop Time (UTCG)']\n",
    "        new_df = pd.DataFrame(columns=filtered_facilities_df.columns)\n",
    "        for index, facility_row in filtered_facilities_df.iterrows():\n",
    "            start_time_facility = facility_row['Start Time (UTCG)']\n",
    "            stop_time_facility = facility_row['Stop Time (UTCG)']\n",
    "            if max(cut_start, start_time_facility) < min(cut_stop, stop_time_facility):\n",
    "                alt_row = facility_row.copy()\n",
    "                if start_time_facility < cut_start:\n",
    "                    facility_row['Stop Time (UTCG)'] = cut_start\n",
    "                    new_df = pd.concat([new_df, facility_row.to_frame(1).T], ignore_index=True)\n",
    "                if stop_time_facility > cut_stop:\n",
    "                    alt_row['Start Time (UTCG)'] = cut_stop\n",
    "                    new_df = pd.concat([new_df, alt_row.to_frame(1).T], ignore_index=True)\n",
    "            else:\n",
    "                new_df = pd.concat([new_df, facility_row.to_frame(1).T], ignore_index=True)\n",
    "        filtered_facilities_df = new_df.copy()\n",
    "    dfs.append(filtered_facilities_df)\n",
    "\n",
    "facilities_df_no_area = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities_df_no_area.reset_index(inplace=True, drop=True)\n",
    "test_df = facilities_df_no_area.copy()\n",
    "test_df['Duration (sec)'] = (test_df['Stop Time (UTCG)'] - test_df['Start Time (UTCG)']).dt.total_seconds()\n",
    "final_no_aree_facilities_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete time intervalsthat are too short\n",
    "seconds_to_split = 30\n",
    "filtered_by_grain = final_no_aree_facilities_df[final_no_aree_facilities_df['Duration (sec)'] >= seconds_to_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@problem_fact\n",
    "class TimeGrain:\n",
    "    def __init__(self, id, start_time, end_time):\n",
    "        self.id = id\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "\n",
    "    @planning_id\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        return (self.end_time - self.start_time) / np.timedelta64(1, 's')\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'TimeGrain(id={self.id}, start_time={self.start_time}, end_time={self.end_time})'\n",
    "\n",
    "@problem_fact\n",
    "class Satellite:\n",
    "    def __init__(self, id, name, capacity, downlink_speed, area_pass_to_data_filmed):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.capacity = capacity\n",
    "        self.downlink_speed = downlink_speed\n",
    "        self.area_pass_to_data_filmed = area_pass_to_data_filmed\n",
    "        self.storage_history_time = {}\n",
    "        self.storage_data_history = {}\n",
    "\n",
    "    @planning_id\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    def get_count_overflow(self):\n",
    "        count_overflow = 0\n",
    "        for key, value in self.storage_data_history.items():\n",
    "            if value > self.capacity:\n",
    "                count_overflow += 1\n",
    "        return count_overflow\n",
    "\n",
    "    def get_count_over_downlink(self):\n",
    "        count_over_downlink = 0\n",
    "        for key, value in self.storage_data_history.items():\n",
    "            if value < 0:\n",
    "                count_over_downlink += 1\n",
    "        return count_over_downlink\n",
    "\n",
    "    # return last data by time stamp when sat was filming\n",
    "    def get_data_filmed_before_time(self, time_stamp: np.datetime64) -> float:\n",
    "        \"\"\"Returns the last data filmed by sat before time_stamp\"\"\"\n",
    "        sat_data = self.area_pass_to_data_filmed\n",
    "        for i in range(len(sat_data)):\n",
    "            if sat_data[i][0] > time_stamp:\n",
    "                if i-1 >= 0:\n",
    "                    return sat_data[i-1][1]\n",
    "                else:\n",
    "                    return 0\n",
    "        return sat_data[-1][1]\n",
    "\n",
    "    def flatten(self, l):\n",
    "        return [item for sublist in l for item in sublist]\n",
    "\n",
    "    def create_storage_data_history(self):\n",
    "        all_time_grains = self.storage_history_time.values()\n",
    "        all_time_grains = self.flatten(all_time_grains)\n",
    "        all_time_grains.sort(key=lambda x: x.start_time)\n",
    "        storage_data_history = {}\n",
    "        data_filmed = 0 # in Tbytes\n",
    "        for time_grain in all_time_grains:\n",
    "            print(time_grain.start_time)\n",
    "            cur_filmed = self.get_data_filmed_before_time(time_grain.start_time)\n",
    "            print(cur_filmed)\n",
    "            if cur_filmed != data_filmed:\n",
    "                data_filmed = cur_filmed\n",
    "                if len(storage_data_history) == 0:\n",
    "                    storage_data_history[time_grain.end_time] = data_filmed - ((time_grain.duration * self.downlink_speed) / 8192)\n",
    "                else:\n",
    "                    storage_data_history[time_grain.end_time] = data_filmed - ((time_grain.duration * self.downlink_speed) / 8192) + storage_data_history[list(storage_data_history)[-1]]\n",
    "            else:\n",
    "                if len(storage_data_history) == 0:\n",
    "                    storage_data_history[time_grain.end_time] = 0\n",
    "                else:\n",
    "                    storage_data_history[time_grain.end_time] = storage_data_history[list(storage_data_history)[-1]] - ((time_grain.duration * self.downlink_speed) / 8192)\n",
    "        self.storage_data_history = storage_data_history\n",
    "\n",
    "    def update_storage_history(self, history: List[TimeGrain], fac_name):\n",
    "        self.storage_history_time[fac_name] = history\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Satellite(id={self.id}, name={self.name})'\n",
    "\n",
    "@problem_fact\n",
    "class Facility:\n",
    "    def __init__(self, id, name, sattelite_visibility_zones: List[List[Tuple[np.datetime64, np.datetime64]]]):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.sattelite_visibility_zones = sattelite_visibility_zones\n",
    "\n",
    "    @planning_id\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    def get_sattelite_visibility_zones(self, sat_id):\n",
    "        return self.sattelite_visibility_zones[sat_id]\n",
    "\n",
    "    def time_grain_fits_zone(self, sat_id, time_grain: TimeGrain):\n",
    "        sat_visibility = self.sattelite_visibility_zones[sat_id]\n",
    "        for start, stop in sat_visibility:\n",
    "            if start <= time_grain.start_time and stop >= time_grain.end_time:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Facility(id={self.id}, name={self.name})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optapy import planning_entity, planning_list_variable\n",
    "\n",
    "def format_list(a_list):\n",
    "    return ',\\n'.join(map(str, a_list))\n",
    "\n",
    "@planning_entity\n",
    "class Assignment:\n",
    "    def __init__(self, id, facility: Facility, satellite: Satellite, time_grains = None):\n",
    "        self.id = id\n",
    "        self.facility = facility\n",
    "        self.satellite = satellite\n",
    "        if time_grains is None:\n",
    "            self.time_grains = []\n",
    "        else:\n",
    "            self.time_grains = time_grains\n",
    "\n",
    "    @planning_id\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    @planning_list_variable(TimeGrain, ['TimeGrain_range'])\n",
    "    def get_time_grains(self):\n",
    "        return self.time_grains\n",
    "\n",
    "    def set_time_grains(self, time_grains):\n",
    "        self.time_grains = time_grains\n",
    "        self.save_taime_grains()\n",
    "\n",
    "    def save_taime_grains(self):\n",
    "        self.satellite.update_storage_history(self.time_grains, self.facility.name)\n",
    "        self.satellite.create_storage_data_history()\n",
    "\n",
    "    def total_downloaded_data(self):\n",
    "        return sum([time_grain.duration * self.satellite.downlink_speed for time_grain in self.time_grains]) / 8192\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Assignment(id={self.id}, facility={self.facility}, satellite={self.satellite}, time_grains={format_list(self.time_grains)})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optapy import constraint_provider\n",
    "from optapy.types import Joiners, HardSoftScore, ConstraintFactory\n",
    "\n",
    "def count_time_grains_overlaping(time_grains_1, time_grains_2):\n",
    "    count = 0\n",
    "    for time_grain_1 in time_grains_1:\n",
    "        for time_grain_2 in time_grains_2:\n",
    "            if time_grain_1.start_time < time_grain_2.end_time and time_grain_1.end_time > time_grain_2.start_time:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def time_grains_fit_vizibility(Assignment):\n",
    "    for time_grain in Assignment.time_grains:\n",
    "        if not Assignment.facility.time_grain_fits_zone(Assignment.satellite.get_id(), time_grain):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "@constraint_provider\n",
    "def define_constraints(constraint_factory: ConstraintFactory):\n",
    "    return [\n",
    "        # Hard constraints\n",
    "        facility_conflict(constraint_factory),\n",
    "        satellite_conflict(constraint_factory),\n",
    "        assignment_time_grains_should_fit_in_visibility_zone(constraint_factory),\n",
    "        data_should_not_be_downloaded_on_empty_storage(constraint_factory),\n",
    "        # Soft constraints\n",
    "        data_storage_optimap_usage(constraint_factory),\n",
    "        total_data_downloaded_should_be_maximized(constraint_factory),\n",
    "    ]\n",
    "\n",
    "def facility_conflict(constraint_factory: ConstraintFactory):\n",
    "    # A facility can only be assigned to one satellite at a time grain\n",
    "    return constraint_factory.for_each(Assignment) \\\n",
    "        .join(Assignment, Joiners.equal(lambda a: a.satellite)) \\\n",
    "        .penalize('Facility conflict', HardSoftScore.ONE_HARD, lambda a1, a2: count_time_grains_overlaping(a1.time_grains, a2.time_grains))\n",
    "\n",
    "def satellite_conflict(constraint_factory: ConstraintFactory):\n",
    "    # Only one sattelite can be assignet at specific time grain in specific facility\n",
    "    return constraint_factory.for_each(Assignment) \\\n",
    "        .join(Assignment, Joiners.equal(lambda a: a.facility)) \\\n",
    "        .penalize('Satellite conflict', HardSoftScore.ONE_HARD, lambda a1, a2: count_time_grains_overlaping(a1.time_grains, a2.time_grains))\n",
    "\n",
    "def assignment_time_grains_should_fit_in_visibility_zone(constraint_factory: ConstraintFactory):\n",
    "    # Time grains of an assignment should fit in the visibility zone of the facility\n",
    "    return constraint_factory.for_each(Assignment) \\\n",
    "        .filter(lambda a: not time_grains_fit_vizibility(a)) \\\n",
    "        .penalize('Assignment time grains should fit in visibility zone', HardSoftScore.ONE_HARD)\n",
    "\n",
    "def data_should_not_be_downloaded_on_empty_storage(constraint_factory: ConstraintFactory):\n",
    "    # Data should not be downloaded on empty storage\n",
    "    return constraint_factory.for_each(Assignment) \\\n",
    "        .penalize('Data should not be downloaded on empty storage', HardSoftScore.ONE_HARD, lambda a: a.satellite.get_count_over_downlink())\n",
    "\n",
    "def data_storage_optimap_usage(constraint_factory: ConstraintFactory):\n",
    "    # Data storage optimap usage\n",
    "    return constraint_factory.for_each(Assignment) \\\n",
    "        .penalize('Data storage optimap usage', HardSoftScore.ONE_SOFT, lambda a: a.satellite.get_count_overflow())\n",
    "\n",
    "def total_data_downloaded_should_be_maximized(constraint_factory: ConstraintFactory):\n",
    "    # Total data downloaded should be maximized\n",
    "    return constraint_factory.for_each(Assignment) \\\n",
    "        .reward('Total data downloaded should be maximized', HardSoftScore.ONE_SOFT, lambda a: a.total_downloaded_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optapy import planning_solution, planning_entity_collection_property, \\\n",
    "    problem_fact_collection_property, \\\n",
    "    value_range_provider, planning_score\n",
    "\n",
    "@planning_solution\n",
    "class TransmissionSchedule:\n",
    "    def __init__(self, facilities: List[Facility], satellites: List[Satellite], assignments: List[Assignment], timegrains: List[TimeGrain], score = None):\n",
    "        self.facilities = facilities\n",
    "        self.satellites = satellites\n",
    "        self.assignments = assignments\n",
    "        self.timegrains = timegrains\n",
    "        self.score = score\n",
    "\n",
    "    def init_sat_storage_history(self):\n",
    "        sat_to_fac_dict = {}\n",
    "        for assignment in self.assignments:\n",
    "            if assignment.facility.name not in sat_to_fac_dict:\n",
    "                sat_to_fac_dict[assignment.facility.name] = []\n",
    "            if assignment.satellite.name not in sat_to_fac_dict[assignment.facility.name]:\n",
    "                assignment.satellite.update_storage_history(assignment.time_grains, assignment.facility.name)\n",
    "                sat_to_fac_dict[assignment.facility.name].append(assignment.satellite.name)\n",
    "            if len(sat_to_fac_dict[assignment.facility.name]) == 200:\n",
    "                assignment.satellite.create_storage_data_history()\n",
    "                sat_to_fac_dict[assignment.facility.name].append('done!')\n",
    "\n",
    "    @problem_fact_collection_property(Facility)\n",
    "    def get_facilities(self):\n",
    "        return self.facilities\n",
    "\n",
    "    @problem_fact_collection_property(Satellite)\n",
    "    def get_satellites(self):\n",
    "        return self.satellites\n",
    "\n",
    "    @problem_fact_collection_property(TimeGrain)\n",
    "    @value_range_provider('TimeGrain_range', value_range_type=list)\n",
    "    def get_time_grains(self):\n",
    "        return self.timegrains\n",
    "\n",
    "    @planning_entity_collection_property(Assignment)\n",
    "    def get_assignments(self):\n",
    "        return self.assignments\n",
    "\n",
    "    @planning_score(HardSoftScore)\n",
    "    def get_score(self):\n",
    "        return self.score\n",
    "\n",
    "    def set_score(self, score):\n",
    "        self.score = score\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"TransmissionSchedule(facilities={format_list(self.facilities)}, satellites={format_list(self.satellites)}, assignments={format_list(self.assignments)}, score={str(self.score.toString()) if self.score is not None else 'None'})\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_names = area_df['sat_name'].unique()\n",
    "sat_names = sorted(sat_names)\n",
    "facilities_name = filtered_by_grain['facility'].unique()\n",
    "facilities_name = sorted(facilities_name)\n",
    "# encode sat names with numbers\n",
    "sat_name_to_num = {name: i for i, name in enumerate(sat_names)}\n",
    "fac_name_to_num = {name: i for i, name in enumerate(facilities_name)}\n",
    "data_filmed_by_sat = []\n",
    "for sat_name in sat_names:\n",
    "    sat_df = area_df[area_df['sat_name'] == sat_name]\n",
    "    # append time as numpy datetime64\n",
    "    data_filmed_by_sat.append(list(zip(sat_df['Stop Time (UTCG)'].to_numpy(), sat_df['Data'])))\n",
    "visibility_slots = []\n",
    "for facility_name in facilities_name:\n",
    "    facility_df = filtered_by_grain[filtered_by_grain['facility'] == facility_name]\n",
    "    sat_visibility = []\n",
    "    for sat_name in sat_names:\n",
    "        sat_df = facility_df[facility_df['sat_name'] == sat_name]\n",
    "        sat_visibility.append(list(zip(sat_df['Start Time (UTCG)'].to_numpy(), sat_df['Stop Time (UTCG)'].to_numpy())))\n",
    "    visibility_slots.append(sat_visibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_solutioin_generator():\n",
    "    \"\"\"Generate initial solution with all facilities assigned to all satellites\"\"\"\n",
    "    facilities: List[Facility] = []\n",
    "    for i, facility_name in enumerate(facilities_name):\n",
    "        facilities.append(Facility(i, facility_name, visibility_slots[i]))\n",
    "    satellites: List[Satellite] = []\n",
    "    for i, sat_name in enumerate(sat_names):\n",
    "        if 'Zorky' in sat_name:\n",
    "            capacity = 0.5\n",
    "            downlink_speed = 0.25\n",
    "        else:\n",
    "            capacity = 1\n",
    "            downlink_speed = 1\n",
    "        satellites.append(Satellite(i, sat_name, capacity, downlink_speed, data_filmed_by_sat[i]))\n",
    "    time_grains = []\n",
    "    assignments = []\n",
    "    grain_index = 0\n",
    "    assignment_index = 0\n",
    "    for fac_num in range(len(facilities)):\n",
    "        for sat_num in range(len(satellites)):\n",
    "            start_grain_index = grain_index\n",
    "            cur_select_df = filtered_by_grain[(filtered_by_grain['facility'] == facilities[fac_num].name) & (filtered_by_grain['sat_name'] == satellites[sat_num].name)]\n",
    "            for _, row in cur_select_df.iterrows():\n",
    "                low_t = row['Start Time (UTCG)']\n",
    "                up_t = row['Stop Time (UTCG)']\n",
    "                time_intervals = np.linspace(low_t.value, up_t.value, int((up_t-low_t).total_seconds()) // seconds_to_split)\n",
    "                time_intervals = np.asarray(time_intervals, dtype='datetime64[ns]')\n",
    "                time_intervals = np.sort(time_intervals)\n",
    "                for time_grain_index in range(len(time_intervals)-1):\n",
    "                    time_interval_start = time_intervals[time_grain_index]\n",
    "                    time_interval_stop = time_intervals[time_grain_index+1]\n",
    "                    # round ns to ms\n",
    "                    time_interval_start = np.datetime64(int(int(int(time_interval_start) / 100000) * 100000), 'ns')\n",
    "                    time_interval_stop = np.datetime64(int(int(int(time_interval_stop) / 100000) * 100000), 'ns')\n",
    "                    time_grains.append(TimeGrain(grain_index, time_interval_start, time_interval_stop))\n",
    "                    grain_index += 1\n",
    "            assignments.append(Assignment(assignment_index, facilities[fac_num], satellites[sat_num], time_grains[start_grain_index:grain_index]))\n",
    "            assignment_index += 1\n",
    "    return TransmissionSchedule(facilities, satellites, assignments, time_grains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_solution = initial_solutioin_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_solution.init_sat_storage_history()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
